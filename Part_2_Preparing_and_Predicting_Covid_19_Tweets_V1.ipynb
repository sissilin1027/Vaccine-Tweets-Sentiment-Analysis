{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "glA-J_fVDBr7"
   },
   "outputs": [],
   "source": [
    "# Code to wrap output\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "def set_css():\n",
    "  display(HTML('''\n",
    "  <style>\n",
    "    pre {\n",
    "        white-space: pre-wrap;\n",
    "    }\n",
    "  </style>\n",
    "  '''))\n",
    "get_ipython().events.register('pre_run_cell', set_css)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "4HgWu5eTJybE",
    "outputId": "a2ac5746-61e1-4843-8d75-00b8efba4a59"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "_US6H3M5L5PJ",
    "outputId": "31376e9b-0648-47bc-dac4-d0a10232bfe1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ktrain\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/67/31cab9d7c0e23333aebc28b082659c1528f9ab7e22d00e7237efe4fc14f6/ktrain-0.26.2.tar.gz (25.3MB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25.3MB 72.9MB/s \n",
      "\u001b[?25hCollecting scikit-learn==0.23.2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f4/cb/64623369f348e9bfb29ff898a57ac7c91ed4921f228e9726546614d63ccb/scikit_learn-0.23.2-cp37-cp37m-manylinux1_x86_64.whl (6.8MB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6.8MB 51.0MB/s \n",
      "\u001b[?25hRequirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from ktrain) (3.2.2)\n",
      "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from ktrain) (1.1.5)\n",
      "Requirement already satisfied: fastprogress>=0.1.21 in /usr/local/lib/python3.7/dist-packages (from ktrain) (1.0.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from ktrain) (2.23.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from ktrain) (1.0.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from ktrain) (20.9)\n",
      "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from ktrain) (5.5.0)\n",
      "Collecting langdetect\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/56/a3/8407c1e62d5980188b4acc45ef3d94b933d14a2ebc9ef3505f22cf772570/langdetect-1.0.8.tar.gz (981kB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 983kB 53.2MB/s \n",
      "\u001b[?25hRequirement already satisfied: jieba in /usr/local/lib/python3.7/dist-packages (from ktrain) (0.42.1)\n",
      "Collecting cchardet\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/72/a4fba7559978de00cf44081c548c5d294bf00ac7dcda2db405d2baa8c67a/cchardet-2.1.7-cp37-cp37m-manylinux2010_x86_64.whl (263kB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 266kB 41.9MB/s \n",
      "\u001b[?25hCollecting syntok\n",
      "  Downloading https://files.pythonhosted.org/packages/8c/76/a49e73a04b3e3a14ce232e8e28a1587f8108baa665644fe8c40e307e792e/syntok-1.3.1.tar.gz\n",
      "Collecting seqeval==0.0.19\n",
      "  Downloading https://files.pythonhosted.org/packages/93/e5/b7705156a77f742cfe4fc6f22d0c71591edb2d243328dff2f8fc0f933ab6/seqeval-0.0.19.tar.gz\n",
      "Collecting transformers<=4.3.3,>=4.0.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f9/54/5ca07ec9569d2f232f3166de5457b63943882f7950ddfcc887732fc7fb23/transformers-4.3.3-py3-none-any.whl (1.9MB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.9MB 48.2MB/s \n",
      "\u001b[?25hCollecting sentencepiece\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.2MB 44.2MB/s \n",
      "\u001b[?25hCollecting keras_bert>=0.86.0\n",
      "  Downloading https://files.pythonhosted.org/packages/e2/7f/95fabd29f4502924fa3f09ff6538c5a7d290dfef2c2fe076d3d1a16e08f0/keras-bert-0.86.0.tar.gz\n",
      "Requirement already satisfied: networkx>=2.3 in /usr/local/lib/python3.7/dist-packages (from ktrain) (2.5.1)\n",
      "Collecting whoosh\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ba/19/24d0f1f454a2c1eb689ca28d2f178db81e5024f42d82729a4ff6771155cf/Whoosh-2.7.4-py2.py3-none-any.whl (468kB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 471kB 49.2MB/s \n",
      "\u001b[?25hRequirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.23.2->ktrain) (1.4.1)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading https://files.pythonhosted.org/packages/f7/12/ec3f2e203afa394a149911729357aa48affc59c20e2c1c8297a60f33f133/threadpoolctl-2.1.0-py3-none-any.whl\n",
      "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.23.2->ktrain) (1.19.5)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.0->ktrain) (2.8.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.0->ktrain) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.0->ktrain) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.0->ktrain) (0.10.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.1->ktrain) (2018.9)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->ktrain) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->ktrain) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->ktrain) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->ktrain) (2020.12.5)\n",
      "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->ktrain) (56.0.0)\n",
      "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->ktrain) (1.0.18)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->ktrain) (0.7.5)\n",
      "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->ktrain) (2.6.1)\n",
      "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->ktrain) (0.8.1)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->ktrain) (4.4.2)\n",
      "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->ktrain) (5.0.5)\n",
      "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.7/dist-packages (from ipython->ktrain) (4.8.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from langdetect->ktrain) (1.15.0)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from syntok->ktrain) (2019.12.20)\n",
      "Requirement already satisfied: Keras>=2.2.4 in /usr/local/lib/python3.7/dist-packages (from seqeval==0.0.19->ktrain) (2.4.3)\n",
      "Collecting tokenizers<0.11,>=0.10.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3.3MB 47.9MB/s \n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers<=4.3.3,>=4.0.0->ktrain) (3.10.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers<=4.3.3,>=4.0.0->ktrain) (4.41.1)\n",
      "Collecting sacremoses\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 901kB 37.6MB/s \n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<=4.3.3,>=4.0.0->ktrain) (3.0.12)\n",
      "Collecting keras-transformer>=0.38.0\n",
      "  Downloading https://files.pythonhosted.org/packages/89/6c/d6f0c164f4cc16fbc0d0fea85f5526e87a7d2df7b077809e422a7e626150/keras-transformer-0.38.0.tar.gz\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->ktrain) (0.2.5)\n",
      "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from traitlets>=4.2->ipython->ktrain) (0.2.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect; sys_platform != \"win32\"->ipython->ktrain) (0.7.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from Keras>=2.2.4->seqeval==0.0.19->ktrain) (3.13)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from Keras>=2.2.4->seqeval==0.0.19->ktrain) (2.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers<=4.3.3,>=4.0.0->ktrain) (3.7.4.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers<=4.3.3,>=4.0.0->ktrain) (3.4.1)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<=4.3.3,>=4.0.0->ktrain) (7.1.2)\n",
      "Collecting keras-pos-embd>=0.11.0\n",
      "  Downloading https://files.pythonhosted.org/packages/09/70/b63ed8fc660da2bb6ae29b9895401c628da5740c048c190b5d7107cadd02/keras-pos-embd-0.11.0.tar.gz\n",
      "Collecting keras-multi-head>=0.27.0\n",
      "  Downloading https://files.pythonhosted.org/packages/e6/32/45adf2549450aca7867deccfa04af80a0ab1ca139af44b16bc669e0e09cd/keras-multi-head-0.27.0.tar.gz\n",
      "Collecting keras-layer-normalization>=0.14.0\n",
      "  Downloading https://files.pythonhosted.org/packages/a4/0e/d1078df0494bac9ce1a67954e5380b6e7569668f0f3b50a9531c62c1fc4a/keras-layer-normalization-0.14.0.tar.gz\n",
      "Collecting keras-position-wise-feed-forward>=0.6.0\n",
      "  Downloading https://files.pythonhosted.org/packages/e3/59/f0faa1037c033059e7e9e7758e6c23b4d1c0772cd48de14c4b6fd4033ad5/keras-position-wise-feed-forward-0.6.0.tar.gz\n",
      "Collecting keras-embed-sim>=0.8.0\n",
      "  Downloading https://files.pythonhosted.org/packages/57/ef/61a1e39082c9e1834a2d09261d4a0b69f7c818b359216d4e1912b20b1c86/keras-embed-sim-0.8.0.tar.gz\n",
      "Collecting keras-self-attention==0.46.0\n",
      "  Downloading https://files.pythonhosted.org/packages/15/6b/c804924a056955fa1f3ff767945187103cfc851ba9bd0fc5a6c6bc18e2eb/keras-self-attention-0.46.0.tar.gz\n",
      "Building wheels for collected packages: ktrain, langdetect, syntok, seqeval, keras-bert, keras-transformer, keras-pos-embd, keras-multi-head, keras-layer-normalization, keras-position-wise-feed-forward, keras-embed-sim, keras-self-attention\n",
      "  Building wheel for ktrain (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for ktrain: filename=ktrain-0.26.2-cp37-none-any.whl size=25277794 sha256=8550be509b38440f05e3196fa6b36d86e39625ce9d777233446ff6ce895704e6\n",
      "  Stored in directory: /root/.cache/pip/wheels/67/2e/f1/c72afa08df8b2d984b910dea228902ce81dae4511afe9fafd2\n",
      "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for langdetect: filename=langdetect-1.0.8-cp37-none-any.whl size=993193 sha256=23b2ec0557b7ca9a8edc8757a95ca3cd27f43047c9132907d2cae742d392aa36\n",
      "  Stored in directory: /root/.cache/pip/wheels/8d/b3/aa/6d99de9f3841d7d3d40a60ea06e6d669e8e5012e6c8b947a57\n",
      "  Building wheel for syntok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for syntok: filename=syntok-1.3.1-cp37-none-any.whl size=20919 sha256=4296a2d868042d744590223a94da73d22ffd7e119fa8943080f3f3472e029d2c\n",
      "  Stored in directory: /root/.cache/pip/wheels/51/c6/a4/be1920586c49469846bcd2888200bdecfe109ec421dab9be2d\n",
      "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for seqeval: filename=seqeval-0.0.19-cp37-none-any.whl size=9919 sha256=f09ff705833f03c5e636f5ff1e0734a4961246da3940eca57d13d84a0e361eb1\n",
      "  Stored in directory: /root/.cache/pip/wheels/8d/1f/bf/1198beceed805a2099060975f6281d1b01046dd279e19c97be\n",
      "  Building wheel for keras-bert (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for keras-bert: filename=keras_bert-0.86.0-cp37-none-any.whl size=34144 sha256=596ece7a867c3d9ea8ce2a2f3b3ab109d44f17502e387d13662955ed12872de2\n",
      "  Stored in directory: /root/.cache/pip/wheels/66/f0/b1/748128b58562fc9e31b907bb5e2ab6a35eb37695e83911236b\n",
      "  Building wheel for keras-transformer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for keras-transformer: filename=keras_transformer-0.38.0-cp37-none-any.whl size=12942 sha256=7ffcc7889706f7c579c933564b388bcaa962116da7b1312867abd9be362978cd\n",
      "  Stored in directory: /root/.cache/pip/wheels/e5/fb/3a/37b2b9326c799aa010ae46a04ddb04f320d8c77c0b7e837f4e\n",
      "  Building wheel for keras-pos-embd (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for keras-pos-embd: filename=keras_pos_embd-0.11.0-cp37-none-any.whl size=7554 sha256=e1261774d086da4e80099acdcb50b1770251e0459d34a6d090fc5f5576f224b2\n",
      "  Stored in directory: /root/.cache/pip/wheels/5b/a1/a0/ce6b1d49ba1a9a76f592e70cf297b05c96bc9f418146761032\n",
      "  Building wheel for keras-multi-head (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for keras-multi-head: filename=keras_multi_head-0.27.0-cp37-none-any.whl size=15611 sha256=dcae0ca39d62906ab0ea372a8b2583fff8e1f6f89eff2452f780e8f4cf821421\n",
      "  Stored in directory: /root/.cache/pip/wheels/b5/b4/49/0a0c27dcb93c13af02fea254ff51d1a43a924dd4e5b7a7164d\n",
      "  Building wheel for keras-layer-normalization (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for keras-layer-normalization: filename=keras_layer_normalization-0.14.0-cp37-none-any.whl size=5269 sha256=cf71d8364ee6547f84a734a352d0f1e8f0369735162d67a2e1c8927e1b8362ba\n",
      "  Stored in directory: /root/.cache/pip/wheels/54/80/22/a638a7d406fd155e507aa33d703e3fa2612b9eb7bb4f4fe667\n",
      "  Building wheel for keras-position-wise-feed-forward (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for keras-position-wise-feed-forward: filename=keras_position_wise_feed_forward-0.6.0-cp37-none-any.whl size=5623 sha256=a7efaa655a51e8f8c3e2b9b5a8f4efc9324a97533e8e2d07f9a6b07e785111c7\n",
      "  Stored in directory: /root/.cache/pip/wheels/39/e2/e2/3514fef126a00574b13bc0b9e23891800158df3a3c19c96e3b\n",
      "  Building wheel for keras-embed-sim (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for keras-embed-sim: filename=keras_embed_sim-0.8.0-cp37-none-any.whl size=4558 sha256=5bc86ffb3aaba98969c341b1862c694cadecfb977dcd941bb99adf7e7486495c\n",
      "  Stored in directory: /root/.cache/pip/wheels/49/45/8b/c111f6cc8bec253e984677de73a6f4f5d2f1649f42aac191c8\n",
      "  Building wheel for keras-self-attention (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for keras-self-attention: filename=keras_self_attention-0.46.0-cp37-none-any.whl size=17278 sha256=d9dcd4c83938f884110028377d51a8430b469ac4e9af530e222e285a1b7aca82\n",
      "  Stored in directory: /root/.cache/pip/wheels/d2/2e/80/fec4c05eb23c8e13b790e26d207d6e0ffe8013fad8c6bdd4d2\n",
      "Successfully built ktrain langdetect syntok seqeval keras-bert keras-transformer keras-pos-embd keras-multi-head keras-layer-normalization keras-position-wise-feed-forward keras-embed-sim keras-self-attention\n",
      "Installing collected packages: threadpoolctl, scikit-learn, langdetect, cchardet, syntok, seqeval, tokenizers, sacremoses, transformers, sentencepiece, keras-pos-embd, keras-self-attention, keras-multi-head, keras-layer-normalization, keras-position-wise-feed-forward, keras-embed-sim, keras-transformer, keras-bert, whoosh, ktrain\n",
      "  Found existing installation: scikit-learn 0.22.2.post1\n",
      "    Uninstalling scikit-learn-0.22.2.post1:\n",
      "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
      "Successfully installed cchardet-2.1.7 keras-bert-0.86.0 keras-embed-sim-0.8.0 keras-layer-normalization-0.14.0 keras-multi-head-0.27.0 keras-pos-embd-0.11.0 keras-position-wise-feed-forward-0.6.0 keras-self-attention-0.46.0 keras-transformer-0.38.0 ktrain-0.26.2 langdetect-1.0.8 sacremoses-0.0.45 scikit-learn-0.23.2 sentencepiece-0.1.95 seqeval-0.0.19 syntok-1.3.1 threadpoolctl-2.1.0 tokenizers-0.10.2 transformers-4.3.3 whoosh-2.7.4\n"
     ]
    }
   ],
   "source": [
    "# Install ktrain\n",
    "!pip install ktrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "id": "JjspCL6-JzWe",
    "outputId": "9b2511b7-3252-4a63-ce79-c56e17b34b6c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      " bert\n",
      "'Colab Notebooks'\n",
      " covid_tweets_cleaned.csv\n",
      "\"Dawson's Documents.pdf\"\n",
      "'Part 2: Predicting and Analyzing Covid-19 Tweets V1.ipynb'\n",
      "'Pre-wedding Shoot'\n",
      "'Quadratic Graphs Booklet.docx'\n",
      "'Quadratic Graphs Booklet.docx.gdoc'\n",
      "'Resume (1).gdoc'\n",
      " Resume.gdoc\n",
      " sentiment140_test.csv\n",
      " sentiment140_train.csv\n",
      " Takeout\n",
      " uscities.csv\n",
      " us_state_capitals.csv\n",
      " us_state_vaccinations.csv\n",
      " vaccination_all_tweets.csv\n",
      "'Video for Bell.mp4'\n"
     ]
    }
   ],
   "source": [
    "# Mount Google Drive to Colab\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# # Change to correct directory\n",
    "import os\n",
    "os.chdir(\"/content/drive/MyDrive\")\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "swponuErJzcF",
    "outputId": "0fafce11-98ef-488e-aff2-7f8507504b8c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import files\n",
    "vac_tweets = pd.read_csv('vaccination_all_tweets.csv')\n",
    "us_vac = pd.read_csv('us_state_vaccinations.csv')\n",
    "# us_cities = pd.read_csv('uscities.csv') # Extra dataset from https://simplemaps.com/data/us-cities \n",
    "us_states = pd.read_csv('us_state_capitals.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "id": "hbnTuDaUJzhE",
    "outputId": "51f8222c-accc-4513-ec87-a0f396d03ff6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_location</th>\n",
       "      <th>user_description</th>\n",
       "      <th>user_created</th>\n",
       "      <th>user_followers</th>\n",
       "      <th>user_friends</th>\n",
       "      <th>user_favourites</th>\n",
       "      <th>user_verified</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>source</th>\n",
       "      <th>retweets</th>\n",
       "      <th>favorites</th>\n",
       "      <th>is_retweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1340539111971516416</td>\n",
       "      <td>Rachel Roh</td>\n",
       "      <td>La Crescenta-Montrose, CA</td>\n",
       "      <td>Aggregator of Asian American news; scanning di...</td>\n",
       "      <td>2009-04-08 17:52:46</td>\n",
       "      <td>405</td>\n",
       "      <td>1692</td>\n",
       "      <td>3247</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-12-20 06:06:44</td>\n",
       "      <td>Same folks said daikon paste could treat a cyt...</td>\n",
       "      <td>['PfizerBioNTech']</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1338158543359250433</td>\n",
       "      <td>Albert Fong</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>Marketing dude, tech geek, heavy metal &amp; '80s ...</td>\n",
       "      <td>2009-09-21 15:27:30</td>\n",
       "      <td>834</td>\n",
       "      <td>666</td>\n",
       "      <td>178</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-12-13 16:27:13</td>\n",
       "      <td>While the world has been on the wrong side of ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1337858199140118533</td>\n",
       "      <td>eliüá±üáπüá™üá∫üëå</td>\n",
       "      <td>Your Bed</td>\n",
       "      <td>heil, hydra üñê‚ò∫</td>\n",
       "      <td>2020-06-25 23:30:28</td>\n",
       "      <td>10</td>\n",
       "      <td>88</td>\n",
       "      <td>155</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-12-12 20:33:45</td>\n",
       "      <td>#coronavirus #SputnikV #AstraZeneca #PfizerBio...</td>\n",
       "      <td>['coronavirus', 'SputnikV', 'AstraZeneca', 'Pf...</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1337855739918835717</td>\n",
       "      <td>Charles Adler</td>\n",
       "      <td>Vancouver, BC - Canada</td>\n",
       "      <td>Hosting \"CharlesAdlerTonight\" Global News Radi...</td>\n",
       "      <td>2008-09-10 11:28:53</td>\n",
       "      <td>49165</td>\n",
       "      <td>3933</td>\n",
       "      <td>21853</td>\n",
       "      <td>True</td>\n",
       "      <td>2020-12-12 20:23:59</td>\n",
       "      <td>Facts are immutable, Senator, even when you're...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>446</td>\n",
       "      <td>2129</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1337854064604966912</td>\n",
       "      <td>Citizen News Channel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Citizen News Channel bringing you an alternati...</td>\n",
       "      <td>2020-04-23 17:58:42</td>\n",
       "      <td>152</td>\n",
       "      <td>580</td>\n",
       "      <td>1473</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-12-12 20:17:19</td>\n",
       "      <td>Explain to me again why we need a vaccine @Bor...</td>\n",
       "      <td>['whereareallthesickpeople', 'PfizerBioNTech']</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id             user_name  ... favorites is_retweet\n",
       "0  1340539111971516416            Rachel Roh  ...         0      False\n",
       "1  1338158543359250433           Albert Fong  ...         1      False\n",
       "2  1337858199140118533              eliüá±üáπüá™üá∫üëå  ...         0      False\n",
       "3  1337855739918835717         Charles Adler  ...      2129      False\n",
       "4  1337854064604966912  Citizen News Channel  ...         0      False\n",
       "\n",
       "[5 rows x 16 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display vaccination tweets\n",
    "vac_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "Clh7g3t2LOK7",
    "outputId": "cbd9ee2b-240a-4dd2-8900-c8ceaf74cbf6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_location</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>la crescenta-montrose, ca</td>\n",
       "      <td>2020-12</td>\n",
       "      <td>Same folks said daikon paste could treat a cyt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>san francisco, ca</td>\n",
       "      <td>2020-12</td>\n",
       "      <td>While the world has been on the wrong side of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>your bed</td>\n",
       "      <td>2020-12</td>\n",
       "      <td>#coronavirus #SputnikV #AstraZeneca #PfizerBio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vancouver, bc - canada</td>\n",
       "      <td>2020-12</td>\n",
       "      <td>Facts are immutable, Senator, even when you're...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>birmingham, england</td>\n",
       "      <td>2020-12</td>\n",
       "      <td>Does anyone have any useful advice/guidance fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40165</th>\n",
       "      <td>italia</td>\n",
       "      <td>2021-03</td>\n",
       "      <td>i want #SputnikV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40166</th>\n",
       "      <td>dublin, ireland</td>\n",
       "      <td>2021-03</td>\n",
       "      <td>Selling: #NitrileGloves, #1860 #FaceMasks, #Va...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40167</th>\n",
       "      <td>geneva, switzerland</td>\n",
       "      <td>2021-03</td>\n",
       "      <td>Limited vaccine manufacturing capacity is a ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40169</th>\n",
       "      <td>sri lanka</td>\n",
       "      <td>2021-03</td>\n",
       "      <td>State Minister of Production, Supply and Regul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40170</th>\n",
       "      <td>—Å—à–∞ üá∫üá∏</td>\n",
       "      <td>2021-03</td>\n",
       "      <td>European micronation #SanMarino begins adminis...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31036 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   user_location  ...                                               text\n",
       "0      la crescenta-montrose, ca  ...  Same folks said daikon paste could treat a cyt...\n",
       "1              san francisco, ca  ...  While the world has been on the wrong side of ...\n",
       "2                       your bed  ...  #coronavirus #SputnikV #AstraZeneca #PfizerBio...\n",
       "3         vancouver, bc - canada  ...  Facts are immutable, Senator, even when you're...\n",
       "5            birmingham, england  ...  Does anyone have any useful advice/guidance fo...\n",
       "...                          ...  ...                                                ...\n",
       "40165                     italia  ...                                   i want #SputnikV\n",
       "40166            dublin, ireland  ...  Selling: #NitrileGloves, #1860 #FaceMasks, #Va...\n",
       "40167        geneva, switzerland  ...  Limited vaccine manufacturing capacity is a ma...\n",
       "40169                  sri lanka  ...  State Minister of Production, Supply and Regul...\n",
       "40170                     —Å—à–∞ üá∫üá∏  ...  European micronation #SanMarino begins adminis...\n",
       "\n",
       "[31036 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set no. of rows displayed\n",
    "pd.set_option(\"display.max_rows\", 10)\n",
    "\n",
    "# Display relevant columns (user_location, date, text/tweet)\n",
    "vac_tweets = vac_tweets[[\"user_location\",\"date\",\"text\"]]\n",
    "\n",
    "# Remove rows with user_location as NaN\n",
    "vac_tweets = vac_tweets.dropna().copy()\n",
    "\n",
    "# Convert strings in user_location to lowercase\n",
    "vac_tweets[\"user_location\"] = vac_tweets[\"user_location\"].str.lower().copy()\n",
    "\n",
    "# Convert date to year and month\n",
    "vac_tweets[\"date\"] = pd.to_datetime(vac_tweets[\"date\"]).dt.to_period('M')\n",
    "\n",
    "vac_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "9d_Yr01KR7C8",
    "outputId": "dbac05c6-95c9-4be0-ea99-92964e1b83ac"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # Select relevant columns\n",
    "# us_cities = us_cities[[\"city\",\"state_id\",\"state_name\"]]\n",
    "\n",
    "# # Convert to lowercase\n",
    "# us_cities [\"city\"] = us_cities [\"city\"].str.lower()\n",
    "# us_cities [\"state_name\"] = us_cities [\"state_name\"].str.lower()\n",
    "\n",
    "# #### Don't include state abbr / id as will get a lot of unwanted matches\n",
    "\n",
    "# us_cities\n",
    "\n",
    "# # Obtain US states as a list\n",
    "# states = list(pd.unique(us_cities[\"state_name\"]))\n",
    "# cities = dict()\n",
    "\n",
    "# # for s in states:\n",
    "# #   c = list(us_cities[us_cities[\"state_name\"] == s][\"city\"])\n",
    "# #   c.append(s)\n",
    "# #   c = \"\\\\b[,]* | \\\\b\".join(c)\n",
    "# #   c = \"\\\\b\" + c + \"\\\\b[,]*\"\n",
    "# #   # print(c)\n",
    "# #   cities[s] = c\n",
    "# #   # break\n",
    "\n",
    "# cities[\"new york\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "wEPlsA6VNNNu",
    "outputId": "dc99bd90-a9a6-4278-dedf-8d46ec34d3a3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>id</th>\n",
       "      <th>capital</th>\n",
       "      <th>combined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>AL</td>\n",
       "      <td>Montgomery</td>\n",
       "      <td>\\balabama\\b|\\bal\\b|\\bmontgomery\\b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>AK</td>\n",
       "      <td>Juneau</td>\n",
       "      <td>\\balaska\\b|\\bak\\b|\\bjuneau\\b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>AZ</td>\n",
       "      <td>Phoenix</td>\n",
       "      <td>\\barizona\\b|\\baz\\b|\\bphoenix\\b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>AR</td>\n",
       "      <td>Little Rock</td>\n",
       "      <td>\\barkansas\\b|\\bar\\b|\\blittle rock\\b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>CA</td>\n",
       "      <td>Sacramento</td>\n",
       "      <td>\\bcalifornia\\b|\\bca\\b|\\bsacramento\\b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Virginia</td>\n",
       "      <td>VA</td>\n",
       "      <td>Richmond</td>\n",
       "      <td>\\bvirginia\\b|\\bva\\b|\\brichmond\\b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Washington</td>\n",
       "      <td>WA</td>\n",
       "      <td>Olympia</td>\n",
       "      <td>\\bwashington\\b|\\bwa\\b|\\bolympia\\b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>West Virginia</td>\n",
       "      <td>WV</td>\n",
       "      <td>Charleston</td>\n",
       "      <td>\\bwest virginia\\b|\\bwv\\b|\\bcharleston\\b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>WI</td>\n",
       "      <td>Madison</td>\n",
       "      <td>\\bwisconsin\\b|\\bwi\\b|\\bmadison\\b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>WY</td>\n",
       "      <td>Cheyenne</td>\n",
       "      <td>\\bwyoming\\b|\\bwy\\b|\\bcheyenne\\b</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            state  id      capital                                 combined\n",
       "0         Alabama  AL   Montgomery        \\balabama\\b|\\bal\\b|\\bmontgomery\\b\n",
       "1          Alaska  AK       Juneau             \\balaska\\b|\\bak\\b|\\bjuneau\\b\n",
       "2         Arizona  AZ      Phoenix           \\barizona\\b|\\baz\\b|\\bphoenix\\b\n",
       "3        Arkansas  AR  Little Rock      \\barkansas\\b|\\bar\\b|\\blittle rock\\b\n",
       "4      California  CA   Sacramento     \\bcalifornia\\b|\\bca\\b|\\bsacramento\\b\n",
       "..            ...  ..          ...                                      ...\n",
       "45       Virginia  VA     Richmond         \\bvirginia\\b|\\bva\\b|\\brichmond\\b\n",
       "46     Washington  WA      Olympia        \\bwashington\\b|\\bwa\\b|\\bolympia\\b\n",
       "47  West Virginia  WV   Charleston  \\bwest virginia\\b|\\bwv\\b|\\bcharleston\\b\n",
       "48      Wisconsin  WI      Madison         \\bwisconsin\\b|\\bwi\\b|\\bmadison\\b\n",
       "49        Wyoming  WY     Cheyenne          \\bwyoming\\b|\\bwy\\b|\\bcheyenne\\b\n",
       "\n",
       "[50 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display all rows\n",
    "pd.set_option(\"display.max_rows\", 10)\n",
    "\n",
    "# Combine state, id and capital into regex pattern\n",
    "us_states[\"combined\"] = \"\\\\b\" + us_states[\"state\"] + \"\\\\b|\\\\b\" + us_states[\"id\"] + \"\\\\b|\\\\b\" + us_states[\"capital\"] +\"\\\\b\"\n",
    "\n",
    "# Convert to lowercase\n",
    "us_states[\"combined\"] = us_states[\"combined\"].str.lower()\n",
    "\n",
    "# Display\n",
    "us_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "00G9HErCjms-",
    "outputId": "de340ecb-6d9b-4fd3-aa8a-32e5f85b55d0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'\\\\bmissouri\\\\b|\\\\bmo\\\\b|\\\\bjefferson city\\\\b'"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "us_states[\"combined\"][24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "7S8K0yrr_TDp",
    "outputId": "d1c09003-a84a-4b6b-fe52-3569efd48bc2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for i in range(len(us_states)):\n",
    "#   pd.set_option(\"display.max_rows\", 20, \"display.max_columns\", 20)\n",
    "#   print(us_states[\"state\"][i])\n",
    "#   display(vac_tweets[vac_tweets[\"user_location\"].str.contains(us_states[\"combined\"][i], regex = True)])\n",
    "#   print()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "id": "01Yei4XackoA",
    "outputId": "faef9bea-e65b-4297-e3d2-226c668f61ac"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "df_by_state = dict()\n",
    "\n",
    "for _, row in us_states.iterrows():\n",
    "  df_by_state[row[\"state\"]] = vac_tweets[vac_tweets[\"user_location\"].str.contains(row[\"combined\"], regex = True)]\n",
    "  df_by_state[row[\"state\"]][\"state\"] = row[\"state\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "giDo4fuhPGe7",
    "outputId": "4e9e8c93-3c09-42e0-f0e3-48d9abba8533"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Further filtering Alabama\n",
    "# pd.set_option(\"display.max_rows\", 10)\n",
    "df_by_state[\"Alabama\"] = df_by_state[\"Alabama\"][df_by_state[\"Alabama\"][\"user_location\"].str.contains(\"\\\\b, al\\\\b|alabama|montgomery\", regex = True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "Lwus0YD8-F3k",
    "outputId": "36e4c26b-60dc-4683-85b7-e6641f833bc7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Further filtering Delaware\n",
    "# pd.set_option(\"display.max_rows\", None)\n",
    "df_by_state[\"Delaware\"] = df_by_state[\"Delaware\"][df_by_state[\"Delaware\"][\"user_location\"].str.contains(\"\\\\b, de\\\\b|delaware|dover\", regex = True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "N9R_X2rw-F9u",
    "outputId": "09b36fd2-b7bf-4f3f-ec73-49e81b21144c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Further filtering Indiana\n",
    "df_by_state[\"Indiana\"] = df_by_state[\"Indiana\"][df_by_state[\"Indiana\"][\"user_location\"].str.contains(\"\\\\bindiana\\\\b|indianapolis\", regex = True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "A0Cak_7N_6Fa",
    "outputId": "c7da7db9-4fed-4e6d-fc9c-6d3c72dade1f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Further filtering Louisiana\n",
    "df_by_state[\"Louisiana\"] = df_by_state[\"Louisiana\"][df_by_state[\"Louisiana\"][\"user_location\"].str.contains(\"\\\\b, la\\\\b$|\\\\blouisiana\\\\b|baton rouge\", regex = True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "xe51krbk_6IN",
    "outputId": "20d46a8c-8e92-4211-a60f-3d701ff8097f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Further filtering Maine\n",
    "df_by_state[\"Maine\"] = df_by_state[\"Maine\"][df_by_state[\"Maine\"][\"user_location\"].str.contains(\"\\\\b, me\\\\b$|\\\\bmaine\\\\b\", regex = True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "s3C8FCyS_6Kk",
    "outputId": "95a031c7-c30d-48a7-a1a7-c04fbc88d2d1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Further filtering Montana\n",
    "df_by_state[\"Montana\"] = df_by_state[\"Montana\"][df_by_state[\"Montana\"][\"user_location\"].str.contains(\"\\\\bmt\\\\b$|\\\\bmontana\\\\b|helena\", regex = True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "OuggzMxv_6M-",
    "outputId": "80635994-fda9-4d44-c6f5-10bcead27f5e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Further filtering Nebraska\n",
    "df_by_state[\"Nebraska\"] = df_by_state[\"Nebraska\"][df_by_state[\"Nebraska\"][\"user_location\"].str.contains(\"\\\\bne\\\\b|\\\\bnebraska\\\\b|lincoln$\", regex = True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "kt5SwTuW-GAs",
    "outputId": "cbe27724-ccce-466a-c23a-9353a32f70a0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Further filtering South Carolina\n",
    "df_by_state[\"South Carolina\"] = df_by_state[\"South Carolina\"][df_by_state[\"South Carolina\"][\"user_location\"].str.contains(\"\\\\bsc\\\\b|\\\\bsouth carolina\\\\b$\", regex = True)]\n",
    "# df_by_state[\"South Carolina\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "iVm_QhZz-GEC",
    "outputId": "97c2aefc-cffb-4e86-d2c6-da382107d778"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the number of tweets for each state\n",
    "\n",
    "# for state, df in df_by_state.items():\n",
    "#   print(state)\n",
    "#   print(df.shape[0])\n",
    "#   print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "sVinBj06HfBi",
    "outputId": "996efb1b-d11c-49a3-ed6a-680948fb8986"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>2020-12</td>\n",
       "      <td>Got the COVID vaccine today. This is amazing. ...</td>\n",
       "      <td>Alabama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1372</th>\n",
       "      <td>2020-12</td>\n",
       "      <td>‚ÄúWe are protecting the high risk.‚Äù -@realDonal...</td>\n",
       "      <td>Alabama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1736</th>\n",
       "      <td>2020-12</td>\n",
       "      <td>I'm grateful for all of the healthcare workers...</td>\n",
       "      <td>Alabama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1829</th>\n",
       "      <td>2020-12</td>\n",
       "      <td>#fomonomo #COVAX #Pfizer #PfizerBioNTech #Pfiz...</td>\n",
       "      <td>Alabama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3061</th>\n",
       "      <td>2021-01</td>\n",
       "      <td>Dr Fun's I Feel Good - My effort at a PSA, ple...</td>\n",
       "      <td>Alabama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27209</th>\n",
       "      <td>2021-03</td>\n",
       "      <td>I  was blessed to got my first Fauci Ouchie ge...</td>\n",
       "      <td>Wyoming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29367</th>\n",
       "      <td>2021-03</td>\n",
       "      <td>yes can we put this Virus behind us #OxfordAst...</td>\n",
       "      <td>Wyoming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32022</th>\n",
       "      <td>2021-03</td>\n",
       "      <td>#secondshot tomorrow my mom and I will receive...</td>\n",
       "      <td>Wyoming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33269</th>\n",
       "      <td>2021-03</td>\n",
       "      <td>Just FYI, y‚Äôall can feel bitter towards me now...</td>\n",
       "      <td>Wyoming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36510</th>\n",
       "      <td>2021-03</td>\n",
       "      <td>*STARTING MONDAY*\\n Louisiana residents 16 YEA...</td>\n",
       "      <td>Wyoming</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6904 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date                                               text    state\n",
       "511    2020-12  Got the COVID vaccine today. This is amazing. ...  Alabama\n",
       "1372   2020-12  ‚ÄúWe are protecting the high risk.‚Äù -@realDonal...  Alabama\n",
       "1736   2020-12  I'm grateful for all of the healthcare workers...  Alabama\n",
       "1829   2020-12  #fomonomo #COVAX #Pfizer #PfizerBioNTech #Pfiz...  Alabama\n",
       "3061   2021-01  Dr Fun's I Feel Good - My effort at a PSA, ple...  Alabama\n",
       "...        ...                                                ...      ...\n",
       "27209  2021-03  I  was blessed to got my first Fauci Ouchie ge...  Wyoming\n",
       "29367  2021-03  yes can we put this Virus behind us #OxfordAst...  Wyoming\n",
       "32022  2021-03  #secondshot tomorrow my mom and I will receive...  Wyoming\n",
       "33269  2021-03  Just FYI, y‚Äôall can feel bitter towards me now...  Wyoming\n",
       "36510  2021-03  *STARTING MONDAY*\\n Louisiana residents 16 YEA...  Wyoming\n",
       "\n",
       "[6904 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned = pd.DataFrame()\n",
    "\n",
    "for state, df in df_by_state.items():\n",
    "  df_cleaned = pd.concat([df_cleaned, df[[\"date\",\"text\",\"state\"]]])\n",
    "  \n",
    "df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "wNr2woHBK87Q",
    "outputId": "47f4e096-b341-4db9-aaa0-72927678e7bb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>state</th>\n",
       "      <th>cleaned_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>2020-12</td>\n",
       "      <td>Got the COVID vaccine today. This is amazing. ...</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>got the covid vaccine today this is amazing so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1372</th>\n",
       "      <td>2020-12</td>\n",
       "      <td>‚ÄúWe are protecting the high risk.‚Äù -@realDonal...</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>we are protecting the high risk bull shit if t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1736</th>\n",
       "      <td>2020-12</td>\n",
       "      <td>I'm grateful for all of the healthcare workers...</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>im grateful for all of the healthcare workers ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1829</th>\n",
       "      <td>2020-12</td>\n",
       "      <td>#fomonomo #COVAX #Pfizer #PfizerBioNTech #Pfiz...</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>fomonomo covax pfizer pfizerbiontech pfizercov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3061</th>\n",
       "      <td>2021-01</td>\n",
       "      <td>Dr Fun's I Feel Good - My effort at a PSA, ple...</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>dr funs i feel good my effort at a psa please ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27209</th>\n",
       "      <td>2021-03</td>\n",
       "      <td>I  was blessed to got my first Fauci Ouchie ge...</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>i was blessed to got my first fauci ouchie get...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29367</th>\n",
       "      <td>2021-03</td>\n",
       "      <td>yes can we put this Virus behind us #OxfordAst...</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>yes can we put this virus behind us oxfordastr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32022</th>\n",
       "      <td>2021-03</td>\n",
       "      <td>#secondshot tomorrow my mom and I will receive...</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>secondshot tomorrow my mom and i will receive ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33269</th>\n",
       "      <td>2021-03</td>\n",
       "      <td>Just FYI, y‚Äôall can feel bitter towards me now...</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>just fyi yall can feel bitter towards me nowiv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36510</th>\n",
       "      <td>2021-03</td>\n",
       "      <td>*STARTING MONDAY*\\n Louisiana residents 16 YEA...</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>starting monday louisiana residents years or o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6904 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date  ...                                      cleaned_tweet\n",
       "511    2020-12  ...  got the covid vaccine today this is amazing so...\n",
       "1372   2020-12  ...  we are protecting the high risk bull shit if t...\n",
       "1736   2020-12  ...  im grateful for all of the healthcare workers ...\n",
       "1829   2020-12  ...  fomonomo covax pfizer pfizerbiontech pfizercov...\n",
       "3061   2021-01  ...  dr funs i feel good my effort at a psa please ...\n",
       "...        ...  ...                                                ...\n",
       "27209  2021-03  ...  i was blessed to got my first fauci ouchie get...\n",
       "29367  2021-03  ...  yes can we put this virus behind us oxfordastr...\n",
       "32022  2021-03  ...  secondshot tomorrow my mom and i will receive ...\n",
       "33269  2021-03  ...  just fyi yall can feel bitter towards me nowiv...\n",
       "36510  2021-03  ...  starting monday louisiana residents years or o...\n",
       "\n",
       "[6904 rows x 4 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Clean dataset ###\n",
    "\n",
    "## Step 1: Remove Twitter handles\n",
    "df_cleaned[\"cleaned_tweet\"] = df_cleaned[\"text\"].str.replace('@[\\w]*',\"\")\n",
    "\n",
    "# Remove leading and trailing whitespaces\n",
    "df_cleaned[\"cleaned_tweet\"] = df_cleaned[\"cleaned_tweet\"].str.strip() \n",
    "\n",
    "## Step 2: Remove URLS\n",
    "pattern = 'https?://[A-Za-z0-9./]+'\n",
    "df_cleaned[\"cleaned_tweet\"] = df_cleaned[\"cleaned_tweet\"].str.replace(pattern,\"\")\n",
    "\n",
    "# Remove leading and trailing whitespaces\n",
    "df_cleaned[\"cleaned_tweet\"] = df_cleaned[\"cleaned_tweet\"].str.strip() \n",
    "\n",
    "## Step 3: Remove punctuations, numbers and special characters (Remove # but keeping words after #)\n",
    "pattern = '[^a-zA-Z\\s]'\n",
    "df_cleaned[\"cleaned_tweet\"] = df_cleaned[\"cleaned_tweet\"].str.replace(pattern,\"\")\n",
    "\n",
    "# Remove leading and trailing whitespaces\n",
    "df_cleaned[\"cleaned_tweet\"] = df_cleaned[\"cleaned_tweet\"].str.strip() \n",
    "\n",
    "# Remove extra spaces\n",
    "df_cleaned[\"cleaned_tweet\"] = df_cleaned[\"cleaned_tweet\"].str.replace(\"\\s{2,10}\",\" \")\n",
    "\n",
    "## Step 4: Convert all words to lowercase\n",
    "df_cleaned[\"cleaned_tweet\"] = df_cleaned[\"cleaned_tweet\"].str.lower()\n",
    "\n",
    "df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "EXJtZPvxLpc8",
    "outputId": "f79cbdea-8817-4224-978d-d7285fac67e3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "############# \n",
    "\n",
    "# Import ktrain\n",
    "import ktrain\n",
    "\n",
    "# Load your predictor\n",
    "predictor = ktrain.load_predictor('/content/drive/MyDrive/bert/predictor-autofit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "fJfxzJ-PMdbo",
    "outputId": "08075036-8daa-47dd-e6a7-48cf62cde863"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "############# \n",
    "\n",
    "# Predict sentiment of tweet \n",
    "prediction = predictor.predict(df_cleaned[\"cleaned_tweet\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "i_F3MOmmVhiN",
    "outputId": "c4b1a2e2-1e17-41cb-c3ce-f5be5e2c079d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>state</th>\n",
       "      <th>cleaned_tweet</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-12</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>got the covid vaccine today this is amazing so...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-12</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>we are protecting the high risk bull shit if t...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-12</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>im grateful for all of the healthcare workers ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-12</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>fomonomo covax pfizer pfizerbiontech pfizercov...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-01</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>dr funs i feel good my effort at a psa please ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6899</th>\n",
       "      <td>2021-03</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>i was blessed to got my first fauci ouchie get...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6900</th>\n",
       "      <td>2021-03</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>yes can we put this virus behind us oxfordastr...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6901</th>\n",
       "      <td>2021-03</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>secondshot tomorrow my mom and i will receive ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6902</th>\n",
       "      <td>2021-03</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>just fyi yall can feel bitter towards me nowiv...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6903</th>\n",
       "      <td>2021-03</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>starting monday louisiana residents years or o...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6904 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  ... prediction\n",
       "0     2020-12  ...   positive\n",
       "1     2020-12  ...   positive\n",
       "2     2020-12  ...   positive\n",
       "3     2020-12  ...   negative\n",
       "4     2021-01  ...   positive\n",
       "...       ...  ...        ...\n",
       "6899  2021-03  ...   positive\n",
       "6900  2021-03  ...   negative\n",
       "6901  2021-03  ...   positive\n",
       "6902  2021-03  ...   positive\n",
       "6903  2021-03  ...   positive\n",
       "\n",
       "[6904 rows x 4 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine prediction with dataframe\n",
    "df_cleaned.reset_index(inplace = True, drop = True)\n",
    "df_cleaned[\"prediction\"] = pd.Series(prediction)\n",
    "df_cleaned = df_cleaned[[\"date\",\"state\",\"cleaned_tweet\",\"prediction\"]]\n",
    "df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "WU-TAI9dMxDR",
    "outputId": "ec863e63-5d5b-4728-ef80-806c73646d73"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Save dataframe to a csv file\n",
    "df_cleaned.to_csv('covid_tweets_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "id": "M5QRL5hFYAim",
    "outputId": "0eab4a49-67a6-4243-d26d-b28221dfe8c3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/amaiya/eli5@tfkeras_0_10_1\n",
      "  Cloning https://github.com/amaiya/eli5 (to revision tfkeras_0_10_1) to /tmp/pip-req-build-4q6tfyif\n",
      "  Running command git clone -q https://github.com/amaiya/eli5 /tmp/pip-req-build-4q6tfyif\n",
      "  Running command git checkout -b tfkeras_0_10_1 --track origin/tfkeras_0_10_1\n",
      "  Switched to a new branch 'tfkeras_0_10_1'\n",
      "  Branch 'tfkeras_0_10_1' set up to track remote branch 'tfkeras_0_10_1' from 'origin'.\n",
      "Requirement already satisfied: attrs>16.0.0 in /usr/local/lib/python3.7/dist-packages (from eli5==0.10.1) (20.3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from eli5==0.10.1) (2.11.3)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from eli5==0.10.1) (1.19.5)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from eli5==0.10.1) (1.4.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from eli5==0.10.1) (1.15.0)\n",
      "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.7/dist-packages (from eli5==0.10.1) (0.23.2)\n",
      "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from eli5==0.10.1) (0.10.1)\n",
      "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.7/dist-packages (from eli5==0.10.1) (0.8.9)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->eli5==0.10.1) (1.1.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18->eli5==0.10.1) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18->eli5==0.10.1) (1.0.1)\n",
      "Building wheels for collected packages: eli5\n",
      "  Building wheel for eli5 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for eli5: filename=eli5-0.10.1-py2.py3-none-any.whl size=106832 sha256=12d307bbaee47ab4843a465726a1b35646cd6df96c043439535dced5783aee09\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-o4dujmec/wheels/51/59/0a/0f48442b8d209583a4453580938d7ba2270aca40edacee6d45\n",
      "Successfully built eli5\n",
      "Installing collected packages: eli5\n",
      "Successfully installed eli5-0.10.1\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/amaiya/eli5@tfkeras_0_10_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 169
    },
    "id": "sYgQkZJLOw1E",
    "outputId": "04631c7d-c415-4006-d8ea-f44dd644f8ef"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        \n",
       "\n",
       "    \n",
       "\n",
       "        \n",
       "\n",
       "        \n",
       "    \n",
       "        \n",
       "        \n",
       "    \n",
       "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
       "            <b>\n",
       "    \n",
       "        y=positive\n",
       "    \n",
       "</b>\n",
       "\n",
       "    \n",
       "    (probability <b>0.996</b>, score <b>5.498</b>)\n",
       "\n",
       "top features\n",
       "        </p>\n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            \n",
       "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
       "                    Contribution<sup>?</sup>\n",
       "                </th>\n",
       "            \n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "            \n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +5.172\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        Highlighted in text (sum)\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 97.11%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.326\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        &lt;BIAS&gt;\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "        \n",
       "\n",
       "        \n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n",
       "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
       "        <span style=\"background-color: hsl(120, 100.00%, 91.62%); opacity: 0.82\" title=\"0.273\">im</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"2.543\">grateful</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.97%); opacity: 0.83\" title=\"0.403\">for</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 99.69%); opacity: 0.80\" title=\"0.002\">all</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.47%); opacity: 0.80\" title=\"0.024\">of</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 99.82%); opacity: 0.80\" title=\"-0.001\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.62%); opacity: 0.82\" title=\"-0.227\">healthcare</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 85.61%); opacity: 0.85\" title=\"-0.590\">workers</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.05%); opacity: 0.80\" title=\"0.034\">around</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.05%); opacity: 0.81\" title=\"-0.167\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.11%); opacity: 0.82\" title=\"0.206\">globe</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 90.49%); opacity: 0.83\" title=\"0.326\">and</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.71%); opacity: 0.81\" title=\"-0.141\">at</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.79%); opacity: 0.80\" title=\"0.041\">for</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.96%); opacity: 0.81\" title=\"-0.096\">keeping</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.45%); opacity: 0.81\" title=\"0.080\">us</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 79.95%); opacity: 0.87\" title=\"0.948\">healthy</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.05%); opacity: 0.82\" title=\"0.209\">and</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 86.11%); opacity: 0.84\" title=\"0.561\">safe</span>\n",
       "    </p>\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See explaining text classification\n",
    "predictor.explain(df_cleaned[\"cleaned_tweet\"].tolist()[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ky-m3SFSMxNF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "gaNL9GZNLpfi",
    "outputId": "65f38927-d913-4cf5-af73-f052547d1227"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # Predict with test data\n",
    "# predicted_labels = predictor.predict(df_test[\"cleaned_tweet\"].tolist())\n",
    "# accuracy = np.sum(df_test[\"sentiment\"] == predicted_labels)/len(predicted_labels)\n",
    "# print(\"Test accuracy: \" + str(round(accuracy*100)) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "teQc05YcJzjp"
   },
   "outputs": [],
   "source": [
    "# Display US Vaccinations Record\n",
    "# us_vac.head()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Part 2: Preparing and Predicting Covid-19 Tweets V1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
